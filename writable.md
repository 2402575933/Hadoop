# hadoop序列化：
由于分布式的特点，在任务的分配上，执行Maptask的任务和执行ReduceTask的任务可能会被分配到不同的节点上，当数据的传输设计到跨服务器时就要考虑如何传输，服务器之间数据不能直接传输，需要进行
相应的转化，数据从服务器A节点传输到服务器B节点之前，在A处需要对数据进行序列化为字节码（或其他传输协议），经过网络传输到另一个节点B后，在B将数据持久化到磁盘之前需要将数据反序列化（换源数据），然后才写入
磁盘。
对于hadoop默认提供的序列化类型而言，已经提前实现了Writable接口并重写了序列化和反序列化的方法，所以这些默认的方法默认都是支持序列化的而不用自己定义，但是对于自定义的javaBean类型而言，
需要自定义设置为序列化类型，既实现Writable接口然后根据业务逻辑要求是否需要支持排序，即可实现序列化。

### 实现序列化的步骤：
- 实现Writable接口
- 反射调用空参构造，需要在javaBean中指定空参构造
- 重写序列化方法
- 注意对变量序列化的顺序和反序列化的顺序要保持一致
- 根据输出格式的需求重写toString方法
- 如果将javaBean放到key中传输，需要支持排序


### 代码实现：
[ClickHere](https://github.com/2402575933/Hadoop/tree/main/example/serialization)
